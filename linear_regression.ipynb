{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from __future__ import division \n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(data, label, w):\n",
    "    \"\"\"\n",
    "        Cost function to evaluate the linear regression model\n",
    "        @Arguments: \n",
    "            data: The dataset in m x n format. Where m is total samples and n is total features per sample. \n",
    "            label: +1/-1 for the data point. \n",
    "            w: The current weights [size: n x 1]\n",
    "        @returns: \n",
    "            cost: The performance of the model on the current dataset. \n",
    "    \"\"\"\n",
    "    m = len(label)\n",
    "    h = np.vstack(np.array([np.sum(j*w) for j in data]))\n",
    "    temp1 = np.power(np.vstack(np.array([h[i] - label[i] for i in xrange(0, len(label))])), 2)\n",
    "    cost = (1/(2*m)) * np.sum(temp1)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent(data, label, w, alpha, numiters):\n",
    "    \"\"\"\n",
    "        Function to optimize cost for linear regression and update weights.\n",
    "        @Arguments: \n",
    "            data: The dataset in m x n format. Where m is total samples and n is total features per sample. \n",
    "            label: +1/-1 for the data point. \n",
    "            w: The current weights [size: n x 1]\n",
    "            alpha: The learning rate for taking steps in gradient descent.\n",
    "            numiters: The number of iterations\n",
    "        @returns: \n",
    "            cost_history: The values of cost function over the iterations\n",
    "            w: The updated weight\n",
    "    \"\"\"\n",
    "    m = len(label)\n",
    "    cost_history = []\n",
    "    numiters = 0\n",
    "    while True: \n",
    "        h = data.dot(w)\n",
    "        diff_hy = np.subtract(h, np.vstack(label))\n",
    "        data_transpose = np.array(data).transpose()\n",
    "        sigma = data_transpose.dot(diff_hy) \n",
    "        temp = np.array(w) - ((alpha/m)*(sigma))\n",
    "        \n",
    "        w = np.vstack(np.array(temp))\n",
    "        new_cost = compute_cost(data, label, w)\n",
    "        cost_history.append(new_cost)\n",
    "        neg_example_mistakes, pos_example_mistakes = eval(data, label, w)\n",
    "        numerrors = len(neg_example_mistakes) + len(pos_example_mistakes)\n",
    "        numiters += 1\n",
    "        if new_cost < 0.5: \n",
    "            plot_linear_reg(data, w, neg_example_mistakes, pos_example_mistakes, numiters)\n",
    "            break\n",
    "    \n",
    "    return cost_history, w, numiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(data, label, w):\n",
    "    pred = np.sign(data.dot(w))\n",
    "    neg_example_mistakes = []\n",
    "    pos_example_mistakes = []\n",
    "    \n",
    "    for i in xrange(0, data.shape[0]):\n",
    "        if label[i] != pred[i] and np.int(label[i]) == 1:\n",
    "            pos_example_mistakes.append(i)\n",
    "        elif label[i] != pred[i] and np.int(label[i]) == -1:\n",
    "            neg_example_mistakes.append(i)\n",
    "    \n",
    "    return neg_example_mistakes, pos_example_mistakes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_linear_reg(data, w, neg_example_mistakes, pos_example_mistakes, numiters):\n",
    "    green_dots = []\n",
    "    red_dots = []\n",
    "    \n",
    "    for i in xrange(0, data.shape[0]):\n",
    "        if i in neg_example_mistakes: \n",
    "            red_dots.append(data[i])\n",
    "        else: \n",
    "            green_dots.append(data[i])\n",
    "    \n",
    "    green_x = []\n",
    "    green_y = []\n",
    "    red_x = []\n",
    "    red_y = []\n",
    "    \n",
    "    for i in green_dots:\n",
    "        green_x.append(i[0])\n",
    "        green_y.append(i[1])\n",
    "        \n",
    "    for i in red_dots:\n",
    "        red_x.append(i[0])\n",
    "        red_y.append(i[1])\n",
    "        \n",
    "    \n",
    "    approx_curve_slope, approx_curve_bias  = -w[0]/w[2], -w[1]/w[2]\n",
    "    \n",
    "    approx_y = np.linspace(0,10)\n",
    "        \n",
    "    approx_x = (((approx_y - approx_curve_bias)/(approx_curve_slope))) + 2.5\n",
    "                \n",
    "    green_trace = go.Scatter(\n",
    "        x = green_x,\n",
    "        y = green_y,\n",
    "        mode = 'markers', \n",
    "        name = 'Correctly classified points'\n",
    "    )\n",
    "    \n",
    "    red_trace = go.Scatter(\n",
    "        x = red_x,\n",
    "        y = red_y,\n",
    "        mode = 'markers', \n",
    "        name = 'Incorrectly classified points'\n",
    "    )\n",
    "    \n",
    "    original_trace = go.Scatter(\n",
    "        x = [5,5],\n",
    "        y = [0,10],\n",
    "        mode = 'lines',\n",
    "        name = 'decision curve'\n",
    "    )\n",
    "    \n",
    "    approx_trace = go.Scatter(\n",
    "        x = approx_x, \n",
    "        y = approx_y,\n",
    "        mode = 'lines', \n",
    "        name = 'Approximated curve'\n",
    "    )\n",
    "    \n",
    "\n",
    "    data = [green_trace, red_trace, original_trace, approx_trace]\n",
    "    layout = go.Layout(title='Evaluating Iteration: {}'.format(numiters), width=800, height=640)\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    py.image.save_as(fig, filename='linear{}.png'.format(numiters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fetching the dataset from PLA. \n",
    "with open('dataset.pickle', 'r') as f: \n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Constructing the data and label. \n",
    "data = []\n",
    "label = []\n",
    "\n",
    "for i in dataset: \n",
    "    data.append(np.array(i))\n",
    "    if i[0] <= 5:\n",
    "        label.append(-1)\n",
    "    else:\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_no_bias = np.vstack(np.array(data))\n",
    "data = np.ones((data_no_bias.shape[0], data_no_bias.shape[1]+1))\n",
    "data[:,:-1] = data_no_bias\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost is: 183.90733096\n"
     ]
    }
   ],
   "source": [
    "#Initializing weights. \n",
    "\n",
    "w = np.vstack(np.array([np.random.random() for i in xrange(data.shape[1])]))\n",
    "alpha = 0.01\n",
    "numiters = 35000\n",
    "\n",
    "print \"Initial Cost is: {}\".format(compute_cost(data, label, w))\n",
    "\n",
    "\n",
    "cost_history, w, iterations = gradient_descent(data, label, w, alpha, numiters)\n",
    "\n",
    "print \"Cost after training {} iterations: {}\".format(iterations, compute_cost(data, label, w))\n",
    "print \"Final weights:\"\n",
    "print w\n",
    "\n",
    "pred = data.dot(w)\n",
    "\n",
    "for i in xrange(0, len(data)):\n",
    "    print \"Datapoint : {}, predicted value: {}\".format(data[i], pred[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
